<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Flexible Recurrent Feature Reasoning for Image Inpainting">
  <meta name="keywords" content="Image Inpainting, Recurrent Strategy, Deep Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Flexible Recurrent Feature Reasoning for Image Inpainting</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <meta property="og:site_name" content="Flexible Recurrent Feature Reasoning for Image Inpainting" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="Flexible Recurrent Feature Reasoning for Image Inpainting" />
  <meta property="og:description" content="Wang, Zhang. Flexible Recurrent Feature Reasoning for Image Inpainting" />
  <meta property="og:url" content="https://wangning-001.github.io/FRFR/" />
  <meta property="og:image" content="https://worldsheet.github.io/static/images/preview.jpg" />
  <meta property="og:image:secure" content="https://worldsheet.github.io/static/images/preview.jpg" />
  <meta property="og:video" content="https://www.youtube.com/embed/j5aT3zRxFlk?rel=0&showinfo=0" />
  <meta property="og:video:secure" content="https://www.youtube.com/embed/j5aT3zRxFlk?rel=0&showinfo=0" />

  <meta property="article:publisher" content="https://pathak22.github.io" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Flexible Recurrent Feature Reasoning for Image Inpainting" />
  <meta name="twitter:description" content="Wang, Zhang. Flexible Recurrent Feature Reasoning for Image Inpainting" />
  <meta name="twitter:url" content="https://worldsheet.github.io/" />
  <meta name="twitter:image" content="https://worldsheet.github.io/static/images/preview.jpg" />
  <!-- <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Deepak Pathak" /> -->
  <!-- <meta name="twitter:label2" content="Filed under" />
  <meta name="twitter:data2" content="" /> -->
  <meta name="twitter:site" content="@pathak2206" />
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="https://www.youtube.com/iframe_api"></script>
  <meta name="twitter:card" content="player" />
  <meta name="twitter:image" content="https://worldsheet.github.io/static/images/preview.jpg" />
  <meta name="twitter:player" content="https://www.youtube.com/embed/j5aT3zRxFlk" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Flexible Recurrent Feature Reasoning for Image Inpainting</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=DL3GDfUAAAAJ">Ning Wang</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://scholar.google.com/citations?user=jtjVV04AAAAJ">‪Jingyuan Li‬</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://sites.google.com/site/lzhangpage/">Lefei Zhang</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="http://cs.whu.edu.cn/aspx/enmain/teacherinfo.aspx?id=254">Bo Du</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a><sup>2</sup>
              <br /><sup>1</sup>Wuhan University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>JD Explore Academy
              <span class="brmod"></span>CVPR 2020 Extension</span>
          </div>

<!--           <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Facebook AI Research,</span>
            <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./resources/FRFR.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2008.03737"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jingyuanli001/RFR-Inpainting" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Existing inpainting methods have achieved promising performance for recovering regular or small image defects. 
			However, filling in large continuous holes remains difficult due to the lack of constraints for the hole center. 
			To address this problem, we devise a Recurrent Feature Reasoning network <strong>(RFR-Net)</strong> which is mainly constructed by 
			a plug-and-play Recurrent Feature Reasoning module and a Knowledge Consistent Attention (KCA) module. Analogous to 
			how humans solve puzzles (i.e., first solve the easier parts and then use the results as additional information to 
			solve difficult parts), the RFR module recurrently infers the hole boundaries of the convolutional feature maps and 
			then uses them as clues for further inference. The module progressively strengthens the constraints for the hole 
			center and the results become explicit. To capture information from distant places in the feature map for RFR, we 
			further develop KCA and incorporate it in RFR. In addition, we propose Flexible RFR-Net <strong>(FRFR)</strong> that enhances the 
			effect without significantly increasing network parameters. In FRFR, to dynamically make use of valid information, 
			we employ a flexible normalization (FN) module, which combines three basic normalization methods to build regular FN 
			(FN-R) and mask-wise FN (FN-M). Extensive experiments comparing the performance with state-of-the-art image inpainting 
			methods demonstrate that both RFR and FRFR improve the qualitative scores, as well as significantly reduce the 
			distortion in quantitative results and obtain realistic images with fine details. What's more, the proposed RFR is 
			applied to the image super-resolution task, which demonstrates the superiority of the RFR module in various image 
			restoration tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
  <!--/ Abstract. -->

</section>


<section class="section">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Method</h2>
        <div class="content has-text-justified">
          <p>
            The masked image is first mapped into the convolutional feature space and processed by a shared Feature Reasoning module recurrently. 
			After the feature map is fully recovered, the generated feature maps are merged together (Omitted in this figure) and the merged feature is translated back to a RGB image.
          </p>
		  <div class="content has-text-centered">
			<img style="width: 80%;" src="./resources/overview.png" />
		  </div>
        </div>
        <br/>

        <!-- Results. -->
        <h3 class="title is-4">Comparison to prior state-of-the-art</h3>
        <div class="content has-text-justified">
		  <h4>Quantitative Evaluation</h4>
          <p>
            We evaluate and compare with previous approaches on three benchmark datasets: Paris StreetView, CelebA, and Places2. Our model outperforms previous work under PSNR and other metrics (see paper for details).
          </p>
        </div>
        <div class="is-vcentered interpolation-panel">
          <div class="content has-text-centered">
            <p>
              Results on Paris StreetView
            </p>
          </div>
		  <div class="content has-text-centered">
            <img style="border: 1px solid #bbb; border-radius: 10px; width: 60%;" src="./resources/paris-t.jpg">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </div>
        </div>
		<div class="is-vcentered interpolation-panel">
          <div class="content has-text-centered">
            <p>
              Results on CelebA
            </p>
          </div>
		  <div class="content has-text-centered">
            <img style="border: 1px solid #bbb; border-radius: 10px; width: 60%;" src="./resources/celeba-t.jpg">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </div>
        </div>
		<div class="is-vcentered interpolation-panel">
          <div class="content has-text-centered">
            <p>
              Results on Places2
          </div>
          <div class="content has-text-centered">
            <img style="border: 1px solid #bbb; border-radius: 10px; width: 60%;" src="./resources/places-t.jpg">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </div>
        </div>
        <br/>
        <br/>

        <!--/ Results. -->
		

      </div>
    </div>

  </div>
</section>


<section class="section" id="Citation">
  <div class="container content">
    <h2 class="title">Citation</h2>
	<a href="./resources/FRFR.pdf"><b>FRFR</b></a>:
	<p>Wang, N., Li, J., Zhang, L., Du, B., & Tao, D. (2021). Flexible Recurrent Feature Reasoning for Image Inpainting. arXiv preprint arXiv:xxxx.xxxxx.</p>
	<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Recurrent_Feature_Reasoning_for_Image_Inpainting_CVPR_2020_paper"><b>RFR</b></a>:
	<p>Li, J., Wang, N., Zhang, L., Du, B., & Tao, D. (2020). Recurrent feature reasoning for image inpainting. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 7760-7768).</p>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="title">BibTeX</h2>
	    <pre><code>@article{wang2021flexible,
  title={Flexible Recurrent feature reasoning for image inpainting},
  author={Wang, Ning and Li, Jingyuan and Zhang, Lefei and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:xxxx.xxxxx},
  year={2021}
}</code></pre>
    <pre><code>@inproceedings{li2020recurrent,
  title={Recurrent feature reasoning for image inpainting},
  author={Li, Jingyuan and Wang, Ning and Zhang, Lefei and Du, Bo and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7760--7768},
  year={2020}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a href="./resources/FRFR.pdf" class="large-font bottom_buttons">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a href="https://github.com/jingyuanli001/RFR-Inpainting" class="large-font bottom_buttons">
        <i class="fab fa-github"></i>
      </a>
      <br />
      <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="nerfies">Nerfies</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
